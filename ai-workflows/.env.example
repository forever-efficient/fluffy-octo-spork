# AI Workflows - Environment Variables

# OFFLINE MODE (AIRPLANE MODE)
# Set to 'true' for completely offline operation (no internet access)
# Set to 'false' to enable external API calls
# Default: true (completely offline)
OFFLINE_MODE=true

# OLLAMA CONFIGURATION
# Ollama host and port (service must be running on this address)
OLLAMA_HOST=http://ollama:11434

# Model to use for LLM inference
# Popular offline options: mistral, neural-chat, orca-mini, llama2
OLLAMA_MODEL=mistral

# REST API CONFIGURATION
# Host and port for the REST API server
API_HOST=0.0.0.0
API_PORT=8000

# TELEGRAM BOT (optional, only if using Telegram entry point)
# Telegram bot token from @BotFather
# Leave empty to disable Telegram bot
TELEGRAM_BOT_TOKEN=

# Internal URL for REST API (used by Telegram bot)
# Inside Docker, service names are used
TELEGRAM_API_URL=http://app:8000
